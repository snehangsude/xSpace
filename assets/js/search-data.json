{
  
    
        "post0": {
            "title": "Audible Data Cleaning",
            "content": "Importing Libraries . We import Pandas and Numpy as the two libraries would help us clean, edit and prepare our scraped data. We also import Warnings. This notebook focused more on data cleaning and data wrangling. For data exploration you can view the notebook here. . import pandas as pd import numpy as np import warnings warnings.simplefilter(&#39;ignore&#39;) # ignore any warnings from any code cell . Reading the data . data = pd.read_csv(&#39;./audible_uncleaned.csv&#39;) data.shape # Gives use a tuple of (rows, columns) . (87489, 8) . data.head(3) . name author narrator time releasedate language stars price . 0 Geronimo Stilton #11 &amp; #12 | Writtenby:GeronimoStilton | Narratedby:BillLobely | 2 hrs and 20 mins | 04-08-08 | English | 5 out of 5 stars34 ratings | 468.00 | . 1 The Burning Maze | Writtenby:RickRiordan | Narratedby:RobbieDaymond | 13 hrs and 8 mins | 01-05-18 | English | 4.5 out of 5 stars41 ratings | 820.00 | . 2 The Deep End | Writtenby:JeffKinney | Narratedby:DanRussell | 2 hrs and 3 mins | 06-11-20 | English | 4.5 out of 5 stars38 ratings | 410.00 | . Cleaning the data . While we have our scraped data, we don&#39;t exactly have a cleaner much readable view of our data or the datatypes for the columns we would prefer before diving into analysis and data visulization. Let&#39;s start by cleaning our data. . Checking for duplicates . We use .sum() method as data.duplicated() returns a Pandas Series of boolean values. Summing them up shows how many duplicated values are there. . data.duplicated().sum() . 0 . Cleaning the author and narrator columns . Removing the Writtenby: and Narratedby: as those values are redundant . Selecting the Pandas Series by using data.author | Then we use the .str method get all the string values | And finally, we run the replace method with the value_to_be_replaced and the value_to_be_replaced_with | . data.author = data.author.str.replace(&#39;Writtenby:&#39;, &#39;&#39;) data.narrator = data.narrator.str.replace(&#39;Narratedby:&#39;, &#39;&#39;) data.sample(3) . name author narrator time releasedate language stars price . 10867 The Trust Manifesto | DamianBradfield | DamianBradfield,RichardHughes,KristinAtherton | 6 hrs and 54 mins | 10-10-19 | English | Not rated yet | 888.00 | . 34136 How to Be a Conscious Eater | SophieEgan | SophieEgan | 7 hrs and 15 mins | 27-04-21 | English | Not rated yet | 562.00 | . 6549 Els silencis de la boca de la mina [The Silenc... | AndreuSotorra | JoanMora | 4 hrs and 3 mins | 02-01-19 | catalan | Not rated yet | 537.00 | . Cleaning the stars columns . The stars column has three distinct format of values: . 5 out of 5 stars34 ratings | 4.5 out of 5 stars38 ratings | Not rated yet | We handle the 3rd one efficiently using the Pandas Series and the replace method to replace with NaN values using the numpy library. Note: This doesn&#39;t use the str method and hence we use the inplace = True | As for the 1st and the 2nd one, we use Regex to split the string into two columns of stars and ratings.Note:I used the Regex101 as guide to use regular expression on the string. . | . data.stars.replace(&#39;Not rated yet&#39;, np.nan, inplace=True) data[[&#39;unknown&#39;,&#39;stars&#39;, &#39;ratings&#39;]] = data.stars.str.split(r&#39;( d*.? d s[a-z]+ s[a-z]+ s d+ s[a-z]+)&#39;, 1, expand=True, regex=True) . data.drop(&#39;unknown&#39;, axis=1, inplace=True) # Dropping the unknown column as it only consists of spaces and nan values . Changing Datatypes . Changing the price column to a float value . The price column has three distinct values: . Free | 3-digit value. Eg:839.00 | 4-digit value. Eg:1,230.00 | We replace 1st one with 0 | And for the 3rd one we remove the , as that blocks us to change the datatype to float | . data.price = data.price.str.replace(&#39;,&#39;, &#39;&#39;) data.price.replace(&#39;Free&#39;, 0, inplace=True) data.price = data.price.astype(&#39;float64&#39;) . Changing the ratings column to a float value . The ratings column has one value: . 23 ratings | We split the data at the -space- and drop the column which doesn&#39;t have the value and then change the datatype to float. Note:Ratings are generally whole numbers but since the column has null values it couldn&#39;t be changed to int and hence the choice for float . | . data[[&#39;ratings&#39;, &#39;unknown&#39;]] = data.ratings.str.split(&#39; &#39;, 1, expand=True) data.drop(&#39;unknown&#39;, axis=1, inplace=True) . data.ratings = data.ratings.str.replace(&#39;,&#39;, &#39;&#39;).astype(&#39;float64&#39;) . Changing the stars column to a float value . The stars column has one value: . 5 out of 5 stars | We split the data at the out and drop the extra column as all the values are rated out of 5 stars and then change the datatype to float. | . data[[&#39;stars&#39;, &#39;unknown&#39;]] = data.stars.str.split(&#39;out&#39;, 1, expand=True) data.drop(&#39;unknown&#39;, axis=1, inplace=True) . data.stars = data.stars.astype(&#39;float64&#39;) . Changing the releasedate to datetime object . data.releasedate = pd.to_datetime(data.releasedate) . Changing the time to datetime integer value of only minutes . The time column has 4 distinct values: . 1 hr | 1 min | 3 hrs and 40 mins | Less than 1 minute | For the 4th option we approx it to 1 min | We then replace the hrs to hr and mins to min, as that would help us genaralize it | . data.time = data.time.str.replace(&#39;Less than 1 minute&#39;, &#39;1 min&#39;) data.time = data.time.str.replace(&#39;mins&#39;, &#39;min&#39;) data.time = data.time.str.replace(&#39;hrs&#39;, &#39;hr&#39;) data.head(3) . name author narrator time releasedate language stars price ratings . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 2 hr and 20 min | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 13 hr and 8 min | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | . 2 The Deep End | JeffKinney | DanRussell | 2 hr and 3 min | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | . Here, we split the time twice, once to separate the hour and again to separate the minutes. This again uses Regex as that makes working with strings extremly easy and handy. . Note:It&#39;s not necessary to split it twice and can be done once by reusing mins however this makes it easier to read and understand. . data[[&#39;unknown&#39;, &#39;hour&#39;, &#39;mins&#39;]] = data[&#39;time&#39;].str.split(r&#39;( d+ hr)&#39;, expand=True, regex=True) data.drop([&#39;unknown&#39;, &#39;mins&#39;], axis =1, inplace=True) . data[[&#39;hr&#39;, &#39;minutes&#39;, &#39;unknown&#39;]] = data[&#39;time&#39;].str.split(r&#39;( d+ min)&#39;, expand=True, regex=True) data.drop([&#39;unknown&#39;, &#39;hr&#39;], axis =1, inplace=True) . Note:We see that we have None values and not np.nan values after splitting the string. We use .applymap() to map the lambda function and them sum them up to see the count of None values. An easier way to find what values you have in a Pandas Series is to run df.name_of_column.unique() to see all unique values. To count the number of unique values in a Pandas Series run df.name_of_column.nunique(). . data.applymap(lambda x: x is None).sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 0 price 0 ratings 0 hour 13406 minutes 1343 dtype: int64 . We fill None values the same as filling Nan values i.e. with fillna() . data.hour.fillna(value=&#39;0 hr&#39;, inplace=True) data.minutes.fillna(value=&#39;0 min&#39;, inplace=True) . data.applymap(lambda x: x is None).sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 0 price 0 ratings 0 hour 0 minutes 0 dtype: int64 . data.head(3) . name author narrator time releasedate language stars price ratings hour minutes . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 2 hr and 20 min | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | 2 hr | 20 min | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 13 hr and 8 min | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | 13 hr | 8 min | . 2 The Deep End | JeffKinney | DanRussell | 2 hr and 3 min | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | 2 hr | 3 min | . Now that we don&#39;t have any null values, we remove the string associated with the numbers - hr from the hour columns and min from the minutes column. To convert the entire time from hours &amp; minutes --&gt; minutes, we need to multiply the hours by 60 and then add the minutes. . After removing the string object we turn the value to an integer and use the .mulitply() method to multiply the Pandas Series. . | Finally, we add the minutes and hour column replacing the time column while dropping the hour and minutes column. . | . data.hour = data.hour.str.replace(&#39;hr&#39;, &#39;&#39;).astype(int).multiply(60) data.minutes = data.minutes.str.replace(&#39;min&#39;, &#39;&#39;).astype(int) data[&#39;time&#39;] = data.minutes + data.hour . data.drop([&#39;hour&#39;, &#39;minutes&#39;], axis=1, inplace=True) . data.head(3) . name author narrator time releasedate language stars price ratings . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 140 | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 788 | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | . 2 The Deep End | JeffKinney | DanRussell | 123 | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | . Replacing the NaN values . We are almost done with cleaning our data however we still have Nan values. While we can have NaN values as it could portray the realistic way on how the data is represented but we would evnetually need to replace it with some value when analysing or visulizating the data. . In majority number of cases, I&#39;ve seen NaN values being replaced by mean or median which in this case wouldn&#39;t be of much help, as the audiobooks doesn&#39;t actually have a rating or star. It&#39;s much preferable to replace the value with zero. . data.isna().sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 72417 price 0 ratings 72417 dtype: int64 . We see an equal number of missing values, just as we expected on the stars and ratings column. To replace then with 0 we can simple write: . data.fillna(0, inplace=True) . We can see that we have no missing values now! Great! To check, we can simply run a sample() and it would show us. Note: sample() select a row randomly, you can pass in a value to get that many number of randomly selected rows. . data.isna().sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 0 price 0 ratings 0 dtype: int64 . data.sample(3) . name author narrator time releasedate language stars price ratings . 40951 Шейх Мансур | АнатолийВиноградов | ВсеволодКузнецов | 61 | 2020-12-21 | russian | 0.0 | 99.0 | 0.0 | . 20151 Life | KeithRichards | StephanRemmler | 400 | 2010-04-11 | german | 0.0 | 367.0 | 0.0 | . 51989 The Ship of Silence | AlbertR.Wetjen | JeffHarding | 52 | 2022-02-18 | English | 0.0 | 53.0 | 0.0 | . Finally, we can view the entire infomation of the cleaned DataFrame using .info() . data.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 87489 entries, 0 to 87488 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 name 87489 non-null object 1 author 87489 non-null object 2 narrator 87489 non-null object 3 time 87489 non-null int64 4 releasedate 87489 non-null datetime64[ns] 5 language 87489 non-null object 6 stars 87489 non-null float64 7 price 87489 non-null float64 8 ratings 87489 non-null float64 dtypes: datetime64[ns](1), float64(3), int64(1), object(4) memory usage: 6.0+ MB . Saving the cleaned dataset . We have cleaned our dataset, and now to save it we use .to_csv() function providing the name of the csv file while setting the index to False. . Important:Not setting the index to False would generate an extra column in the csv with row numbers i.e. 0-87488. . data.to_csv(&#39;audible_cleaned.csv&#39;, index=False) .",
            "url": "https://snehangsude.github.io/xSpace/audible/data_wrangling/data_cleaning/tabular_data/2022/04/11/audible-cleaner.html",
            "relUrl": "/audible/data_wrangling/data_cleaning/tabular_data/2022/04/11/audible-cleaner.html",
            "date": " • Apr 11, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "The Brotherhood of : `__str__` & `__repr__`",
            "content": "Diving in the nitty-gritty details of Python introduces us to Dunder Methods. Dunder means &quot;double underscores&quot; as it starts and ends with two underscores. A dunder method acts as a contract between the Python interpreter and the person who made a particular Python class. . For example, the len method, it helps us with the length of any given string or list or a dictionary, however, it uses a dunder method len. Since the length of something is fundamental to any programming language it was made a built-in method but nonetheless, it internally delegates the task to len. . integers = [1, 2, 3, 4, 5] . print(len(integers)) . 5 . print(integers.__len__()) . 5 . There are quite a few built-in functions that internally use dunder methods to work, such as indexing which uses __getitem__, or print which uses __str__. If you are interested to know about all dunder methods here&#39;s a good resource: Dunder Methods. . The Difference . Understanding __str__ &amp; __repr__ allows us greater control for us to not only edit and upgrade classes but also to debug and create libraries. In a nutshell, if I had to explain to you about __str__ or __repr__ they both do the same thing i.e. they print an output. However, __repr__ is mostly used by programmers to debug, and __str__ is for the users using the program. Let&#39;s dive in to see how exactly are they both different and learn about when to use which! . repr(&#39;Triceratops&#39;) . &#34;&#39;Triceratops&#39;&#34; . str(&#39;Triceratops&#39;) . &#39;Triceratops&#39; . Looking at the above lines of code, there isn&#39;t much difference apart from the fact that repr(&#39;Triceratops&#39;) throws us an output which is within a double-inverted comma (&quot;&quot;) and then the string within a single-inverted (&#39;&#39;) comma. As for the str(&#39;Triceratops&#39;) it&#39;s within a single-inverted comma(&#39;&#39;). If you ask me, that&#39;s not even a difference as both of them do the same exact thing and there isn&#39;t much difference. . Let&#39;s look at something a bit more interesting. . import datetime . current_time = datetime.datetime.now() print(current_time) . 2022-03-03 02:10:02.973209 . str(current_time) . &#39;2022-03-03 02:10:02.973209&#39; . repr(current_time) . &#39;datetime.datetime(2022, 3, 3, 2, 10, 2, 973209)&#39; . Fascinating, isn&#39;t it! While using the datetime library we created a variable current_time which stores as the variable says, the current time. Running a print statement gives us an output that is similar to the output when we use the current_time variable inside the str() function. A user-friendly output of the variable giving is the year-month-date hour:minutes:seconds. . However, using the same variable inside the repr() function gives us an entirely different output. It tells us that it&#39;s a datetime object which holds the values (year, month, day, hour, minutes, seconds, microseconds). A developer-friendly output that provides adequate information for a developer to understand. . The Brotherhood . While it may be intriguing to prefer one over another, truth be told, we need both of them to make sure they cover both cases. The general idea is to make the __repr__ function help you as much as you can with maximum details. While the __str__ function with the minimum details which a user can read or understand. For example: . Defining a class: . class Dinosaur: def __init__(self, name): self.name = name def __repr__(self): return (f&#39;{self.name.__class__.__name__}({self.name})&#39;) def __str__(self): return (f&#39;{self.name}&#39;) . dino = Dinosaur(1) print(dino) . 1 . str(dino) . &#39;1&#39; . repr(dino) . &#39;int(1)&#39; . . Note: __class__ and __name__ represents the name of the class the name belongs to. . Conclusion . Now that, you have got a grasp into what __repr__ &amp; __str__ does, you are one step closer to debugging your own code. Try creating a class that gives you all the information using repr() but only the necessary one using str(). . If you are interested to know about how datetime wrote their library __repr__ and __str__ function, you can see the source code here. It might be overwhelming when you look at the code but try to search through the document to find __str__ and __repr__. Hint: Use Ctrl + F. This will give you a broader idea of how these functions are different, yet so similar. . Oh! Something to note, Jupyter notebooks use __repr__ when the output is requested without the print statement. . dino . int(1) . You can view my other articles here. I would much like to connect with you, if you would like to do so too, please connect with me on Twitter. .",
            "url": "https://snehangsude.github.io/xSpace/python/dunder_method/oop/2022/03/03/first.html",
            "relUrl": "/python/dunder_method/oop/2022/03/03/first.html",
            "date": " • Mar 3, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://snehangsude.github.io/xSpace/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://snehangsude.github.io/xSpace/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Hi, I’m Snehangsu De. I am a Data Analyst based in India. I love working with data while creating aesthetic, sometimes interactive data visualizations. The idea is to make decision making easier with the use of data and provide insights into the story, the data tells us. Normally, I work with Python, while recently I’m also diving into the Julia programming language. . This blog contains Notebooks, few topics which I write about are below: . Kaggle Notebooks | Tree-based modelling notebooks | Deep Learning Notebooks | Miscellaneous, which normally contains tougher concepts explained in code format. | . I have an additional blog in Hashnode, you can find it here.This contains hard to understand concepts explained in a visual way. . Additionally, you can view my website here, which contains my public projects. .",
          "url": "https://snehangsude.github.io/xSpace/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://snehangsude.github.io/xSpace/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}