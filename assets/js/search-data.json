{
  
    
        "post0": {
            "title": "Audible - Exploratory Data Analysis",
            "content": "Importing Libraries . While cleaning we have already imported Numpy and Pandas. Pandas and Numpy are essential for analysing the data. If you want to view the notebook where I cleaned the data, please click here. We additionaly import : . Matplotlib, which will help us in creating data visualiation. | Seaborn, which is built on top of matplotlib with a quick &amp; easy API for data plots &amp; a thrid-party library | adjustText which will help us in labelling our plots. | We also import matplotlib.ticker which helps us generate the minor ticks in our plots. . Important: If you get a Module not found error un-comment the below cell. | . . import numpy as np import pandas as pd import matplotlib as mpl import matplotlib.pyplot as plt import seaborn as sns # helps with arranging the texts in our plot from adjustText import adjust_text # helps with minor ticks in the plots from matplotlib.ticker import MultipleLocator import warnings warnings.filterwarnings(&#39;ignore&#39;) . . Setting a few parameters for matplotlib . mpl.rcParams[&#39;axes.facecolor&#39;] = &#39;#222222&#39; # helps with the background color # removes the axes of all the plots, makes it visually aesthetic mpl.rcParams[&#39;axes.spines.right&#39;] = False mpl.rcParams[&#39;axes.spines.top&#39;] = False mpl.rcParams[&#39;axes.spines.left&#39;] = False mpl.rcParams[&#39;axes.spines.bottom&#39;] = False # changing the tick sizes for better viewing plt.rcParams[&#39;xtick.labelsize&#39;]=12 plt.rcParams[&#39;ytick.labelsize&#39;]=12 # Changing to Heiti font as we have Chinese fonts mpl.rcParams[&#39;font.family&#39;] = [&#39;Heiti TC&#39;] . . Reading the cleaned data . df = pd.read_csv(&#39;./audible_cleaned.csv&#39;) df.head(3) . name author narrator time releasedate language stars price ratings . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 140 | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 788 | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | . 2 The Deep End | JeffKinney | DanRussell | 123 | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | . Basic exploration . While we know the shape of our dataset and the fact that we have removed all duplicate values, all null values in the Audible - Cleaner notebook but generally it&#39;s a great start working with any dataset to check for them. . print(f&#39;Null values in the dataset: {df.isna().sum().sum()}&#39;) print(&#39;-&#39; * 30) print(f&#39;Duplicate values in the dataset: {df.duplicated().sum()}&#39;) print(&#39;-&#39; * 30) print(f&#39;Shape of our dataset: {df.shape}&#39;) . Null values in the dataset: 0 Duplicate values in the dataset: 0 Shape of our dataset: (87489, 9) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 87489 entries, 0 to 87488 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 name 87489 non-null object 1 author 87489 non-null object 2 narrator 87489 non-null object 3 time 87489 non-null int64 4 releasedate 87489 non-null object 5 language 87489 non-null object 6 stars 87489 non-null float64 7 price 87489 non-null float64 8 ratings 87489 non-null float64 dtypes: float64(3), int64(1), object(5) memory usage: 6.0+ MB . Runninng the built-in method info() in Pandas, we can come to a few conclusion about our data. We have: . 3 columns of datatype float64 | 1 column of datatype int64 | 5 columns of datatype objectNote:We would need to convert the releasedate to a datetime object as that would give us much more detailed view on understanding our data. . | . df.describe().T.style.bar(subset=&#39;mean&#39;, color=&#39;crimson&#39;).background_gradient(subset=[&#39;50%&#39;], cmap=&#39;coolwarm&#39;) . &nbsp; count mean std min 25% 50% 75% max . time 87489.000000 | 417.497663 | 364.559399 | 1.000000 | 142.000000 | 386.000000 | 584.000000 | 8595.000000 | . stars 87489.000000 | 0.767811 | 1.709640 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 5.000000 | . price 87489.000000 | 559.009246 | 336.096642 | 0.000000 | 268.000000 | 585.000000 | 755.000000 | 7198.000000 | . ratings 87489.000000 | 3.723371 | 86.499601 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 12573.000000 | . Quite a few steps. Let&#39;s break them down. . Pandas comes with a basic data analysis method describe() that gives us information on mean, std(standard deviation), minimum, maximum, 25 percentile, 50 percentile &amp; 75 percentile. | The .T simply transposes the dataframe. | .style.bar is a way to highlight subsets in the dataframe. Here, we select the mean and compare it with the 50 percentile to see how our data is distributed. | Insights: . We see that our mean for the time column is higher than the 50% meaning our data may be right skewed. | While the price column looks like well balanced with heavy outliers. | . In-depth exploration . The goal here is to dive into our dataset looking at the the data trends, distribution , outliers and view comparison between the columns, creating informative &amp; aesthetic data visualization. . %matplotlib inline author_titles = df.author.value_counts().sort_values(ascending=False)[:10] fig, ax = plt.subplots(figsize=(15, 5), facecolor=&#39;#2b2b2b&#39;) sns.barplot(x=author_titles.values, y=author_titles.index, orient=&#39;h&#39;, color=&#39;steelblue&#39;) ax.bar_label(ax.containers[0], color=&#39;lightcyan&#39;, size=11, padding=4) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Authors&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Top 10 authors with highest number of titles&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . Let&#39;s break down the code. . %matplotlib inline helps generate a matplotlib graph inside the Jupyter notebook | value_counts() counts the number the unique values &amp; sort_values() arrangeds the values in an ascending order. | Post that we create a figure &amp; a single axes using plt.subplots. figsize takes a tuple of (width, height) and facecolor is the outer color of the plot. | Then we use the Seaborn library to create a barplot. | ax.bar_label allows us to add label to a bar plot. ax.containers represent an container object which holds the 10 values of the graph.(Here, it&#39;s 10 objects) | ax.tick_params represents the ticks and the associated markers. | ax.set_xlabel represents the label of x-axis. | ax.set_title represents the title of the plot. | ax.grid represents the grid structure or the dotted lines in behind. alpha controls the opacity &amp; ls the linestyle. | plt.show() helps display the graph. . | labelpad,padding,pad controls the padding in between the label and respective object. . | . %matplotlib inline narrator_titles = df.narrator.value_counts().sort_values(ascending=False)[:10] fig, ax = plt.subplots(figsize=(15, 5), facecolor=&#39;#2b2b2b&#39;) sns.barplot(x=narrator_titles.values, y=narrator_titles.index, orient=&#39;h&#39;, color=&#39;steelblue&#39;) ax.bar_label(ax.containers[0], color=&#39;lightcyan&#39;, size=11, padding=4) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Narrators&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Top 10 narrators with highest number of titles&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.text(x=500, y=6, s=&quot;We see that the highest number of narrations done nare &#39;anonymous&#39; followed by &#39;uncredited&#39; in fourth.&quot;, color=&#39;azure&#39;, size=14) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . %matplotlib inline narrator_titles = df.language.value_counts().sort_values(ascending=False)[:10] fig, ax = plt.subplots(figsize=(15, 5), facecolor=&#39;#2b2b2b&#39;) sns.barplot(x=narrator_titles.values, y=narrator_titles.index, orient=&#39;h&#39;, color=&#39;steelblue&#39;) ax.bar_label(ax.containers[0], color=&#39;lightcyan&#39;, size=11, padding=4) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Language&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Top 10 language with highest number of titles&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . Distribution of time . %matplotlib inline fig, ax = plt.subplots(figsize=(18, 5), facecolor=&#39;#2b2b2b&#39;) sns.histplot(df, x=df.time, kde=True, bins=300, color=&#39;steelblue&#39;, line_kws={&#39;linewidth&#39;: 3}) ax.lines[0].set_color(&#39;crimson&#39;) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Time in minutes&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Distribution of time&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.text(x=3000, y=6000, s=&quot;As expected, we see that time is highly right skewed.&quot;, color=&#39;azure&#39;, size=14) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . %matplotlib inline fig, ax = plt.subplots(figsize=(18, 5), facecolor=&#39;#2b2b2b&#39;) flierprops = dict(markerfacecolor=&#39;skyblue&#39;, markersize=7, marker = &#39;o&#39;, markeredgecolor=&#39;#06113C&#39;) sns.boxplot(x=df.time, color=&#39;steelblue&#39;, flierprops=flierprops, linewidth=2.5,) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Time in minutes&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Viewing outliers in time&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . Distribution of price . %matplotlib inline fig, ax = plt.subplots(figsize=(18, 5), facecolor=&#39;#2b2b2b&#39;) sns.histplot(df, x=df.price, kde=True, bins=300, color=&#39;steelblue&#39;, line_kws={&#39;linewidth&#39;: 3}) ax.lines[0].set_color(&#39;crimson&#39;) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Price&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Distribution of price&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.text(x=3000, y=3500, s=&quot;After looking into the distribution of price nit seems that this too is right skewed, with outliers.&quot;, color=&#39;azure&#39;, size=14) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . %matplotlib inline fig, ax = plt.subplots(figsize=(18, 5), facecolor=&#39;#2b2b2b&#39;) flierprops = dict(markerfacecolor=&#39;skyblue&#39;, markersize=7, marker = &#39;o&#39;, markeredgecolor=&#39;#06113C&#39;) sns.boxplot(x=df.price, color=&#39;steelblue&#39;, flierprops=flierprops,linewidth=2.5) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Price&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Viewing outliers in price&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . Distribution of stars . %matplotlib inline fig, ax = plt.subplots(figsize=(18, 5), facecolor=&#39;#2b2b2b&#39;) sns.histplot(df, x=df.ratings, kde=True, bins=300, color=&#39;steelblue&#39;, line_kws={&#39;linewidth&#39;: 3}) ax.lines[0].set_color(&#39;crimson&#39;) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Ratings&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Distribution of ratings&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.text(x=4500, y=80000, s=&quot;Ratings are highly right skewed. nIf we continue to work with this data for modelling, nwe definelty need to transform the data.&quot;, color=&#39;azure&#39;, size=14) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . %matplotlib inline fig, ax = plt.subplots(figsize=(18, 5), facecolor=&#39;#2b2b2b&#39;) stars_count = df.stars.value_counts() sns.barplot(x= stars_count.index, y=stars_count.values, color=&#39;steelblue&#39;,) ax.bar_label(ax.containers[0], color=&#39;lightcyan&#39;, size=13, padding=0) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Stars&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Count of stars&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.grid(alpha=0.2, ls=&#39;:&#39;) plt.show() . . Trend of released audiobooks by year . df.releasedate = pd.to_datetime(df.releasedate) df[&#39;year&#39;] = pd.DatetimeIndex(df[&#39;releasedate&#39;]).year . We use pd.DatetimeIndex to tap into the datetime object and extract the year using the attribute year . df.head(3) . name author narrator time releasedate language stars price ratings year . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 140 | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | 2008 | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 788 | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | 2018 | . 2 The Deep End | JeffKinney | DanRussell | 123 | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | 2020 | . yearly_books = df.year.value_counts().sort_index() fig, ax = plt.subplots(figsize=(18, 5), facecolor=&#39;#2b2b2b&#39;) sns.lineplot(x= yearly_books.index, y=yearly_books.values, color=&#39;steelblue&#39;, linewidth=3, marker=&#39;o&#39;) ax.tick_params(axis=&#39;x&#39;, which=&#39;both&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Stars&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Count&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Number of audiobooks released by year&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.xaxis.set_minor_locator(MultipleLocator(1)) ax.grid(alpha=0.4, ls=&#39;:&#39;, which=&#39;major&#39;) ax.grid(alpha=0.1, ls=&#39;--&#39;, which=&#39;minor&#39;) plt.show() . . Insights: . We see that the first audiobook was released as early as 1998. | Currently, we have data of pre-planned releases planned on 2025. | Looking at the trend, audiobooks started gaining popularity from 2003 hitting the highest on 2021 as of today(April 7, 2022) | . Checking the relationship between ratings and price . fig, ax = plt.subplots(figsize=(22, 7), facecolor=&#39;#2b2b2b&#39;) sp = ax.scatter(x=df.ratings, y=df.price, c=df.stars, cmap=&#39;crest_r&#39;, edgecolor=&#39;#3A3845&#39;, s=110, alpha=0.8) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Ratings&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Price&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Relationship between price and ratings with stars&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) texts= [] checker = [] for rating, amount, name in zip(df.ratings, df.price, df.name): if (rating) &gt; 4000: if name not in checker: checker.append(name) texts.append(ax.text(rating, amount, name, fontdict=dict(color=&#39;azure&#39;, size=15))) adjust_text(texts, force_points=0.5, force_text=3.5, expand_points=(1.2, 5.3), expand_text=(0.9,0.9), autoalign=True, arrowprops=dict(arrowstyle = &#39;-&gt;&#39;, alpha=0.3, lw=2, color=&#39;#B4A5A5&#39;,)) ax.grid(alpha=0.2, ls=&#39;:&#39;, which=&#39;major&#39;) cb = plt.colorbar(sp) cb.set_label(&#39;Stars&#39;, color=&#39;lavender&#39;, fontsize=18) cb.ax.yaxis.set_tick_params(color=&#39;lavender&#39;, size=5) plt.setp(plt.getp(cb.ax.axes, &#39;yticklabels&#39;), color=&#39;lavender&#39;) plt.show() . Code: . ax.scatter is a creating a scatter plot, this is using matplotlib and not seaborn like before | adjust_text is a library that helps you arrange text positions in matplotlib related plots. Here&#39;s the docs. | plt.colorbar generates the color bar on the right | setp &amp; getp sets and gets the property of an object respectively, here it&#39;s the axes of the colorbar | . Insights: . The higest ratings of a audiobook till date is for Atomic Habits with 1,25,690 | . Relationship between year and lenght of audiobooks . fig, ax = plt.subplots(figsize=(22, 7), facecolor=&#39;#2b2b2b&#39;) sp = ax.scatter(x=df.year, y=df.time, c=df.stars, cmap=&#39;crest_r&#39;, edgecolor=&#39;#3A3845&#39;, s=110, alpha=0.8) ax.tick_params(axis=&#39;x&#39;, which=&#39;both&#39;, colors=&#39;gray&#39;, size=8) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=8) ax.set_xlabel(&#39;Year&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_ylabel(&#39;Time in minutes&#39;, fontsize=16, color=&#39;lavender&#39;,labelpad=20) ax.set_title(&#39;Yearly relationship with length of audiobooks&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) ax.xaxis.set_minor_locator(MultipleLocator(1)) ax.text(x=2001, y=6000, s=&quot;We see a trend that the length of audiobooks nincreased over time, with the longest on 2019.&quot;, color=&#39;azure&#39;, size=14) ax.grid(alpha=0.2, ls=&#39;:&#39;, which=&#39;major&#39;) cb = plt.colorbar(sp) cb.set_label(&#39;Stars&#39;, color=&#39;lavender&#39;, fontsize=18) cb.ax.yaxis.set_tick_params(color=&#39;lavender&#39;, size=5) plt.setp(plt.getp(cb.ax.axes, &#39;yticklabels&#39;), color=&#39;lavender&#39;) plt.show() . . Heatmap of all co-related columns . co_relation = df.corr() mapped = np.triu(np.ones_like(co_relation)) fig, ax = plt.subplots(figsize=(18, 7), facecolor=&#39;#2b2b2b&#39;) sns.heatmap(co_relation, mask=mapped, annot=True, cmap=&#39;crest&#39;, linewidths=3, linecolor=&#39;#222222&#39;, cbar=False) ax.tick_params(axis=&#39;x&#39;, colors=&#39;gray&#39;, size=15) ax.tick_params(axis=&#39;y&#39;, colors=&#39;gray&#39;, size=15) ax.text(x=2.5, y=2, s=&quot;We see a postive co-relation with time and price. nIf the time of an audibook increases the price increases too.&quot;, color=&#39;azure&#39;, size=14) ax.set_title(&#39;Co-relation between each columns&#39;, color=&#39;lavender&#39;, fontsize=20, pad=20) plt.show() . .",
            "url": "https://snehangsude.github.io/xSpace/audible/data_analysis/data_visulization/tabular_data/matplotlib/seaborn/2022/04/11/audible-eda.html",
            "relUrl": "/audible/data_analysis/data_visulization/tabular_data/matplotlib/seaborn/2022/04/11/audible-eda.html",
            "date": " • Apr 11, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Audible Data Cleaning",
            "content": "Importing Libraries . We import Pandas and Numpy as the two libraries would help us clean, edit and prepare our scraped data. We also import Warnings. This notebook focused more on data cleaning and data wrangling. For data exploration you can view the notebook here. . You can find and download the data here. . import pandas as pd import numpy as np import warnings warnings.simplefilter(&#39;ignore&#39;) # ignore any warnings from any code cell . Reading the data . data = pd.read_csv(&#39;./audible_uncleaned.csv&#39;) data.shape # Gives use a tuple of (rows, columns) . (87489, 8) . data.head(3) . name author narrator time releasedate language stars price . 0 Geronimo Stilton #11 &amp; #12 | Writtenby:GeronimoStilton | Narratedby:BillLobely | 2 hrs and 20 mins | 04-08-08 | English | 5 out of 5 stars34 ratings | 468.00 | . 1 The Burning Maze | Writtenby:RickRiordan | Narratedby:RobbieDaymond | 13 hrs and 8 mins | 01-05-18 | English | 4.5 out of 5 stars41 ratings | 820.00 | . 2 The Deep End | Writtenby:JeffKinney | Narratedby:DanRussell | 2 hrs and 3 mins | 06-11-20 | English | 4.5 out of 5 stars38 ratings | 410.00 | . Cleaning the data . While we have our scraped data, we don&#39;t exactly have a cleaner much readable view of our data or the datatypes for the columns we would prefer before diving into analysis and data visulization. Let&#39;s start by cleaning our data. . Checking for duplicates . We use .sum() method as data.duplicated() returns a Pandas Series of boolean values. Summing them up shows how many duplicated values are there. . data.duplicated().sum() . 0 . Cleaning the author and narrator columns . Removing the Writtenby: and Narratedby: as those values are redundant . Selecting the Pandas Series by using data.author | Then we use the .str method get all the string values | And finally, we run the replace method with the value_to_be_replaced and the value_to_be_replaced_with | . data.author = data.author.str.replace(&#39;Writtenby:&#39;, &#39;&#39;) data.narrator = data.narrator.str.replace(&#39;Narratedby:&#39;, &#39;&#39;) data.sample(3) . name author narrator time releasedate language stars price . 10867 The Trust Manifesto | DamianBradfield | DamianBradfield,RichardHughes,KristinAtherton | 6 hrs and 54 mins | 10-10-19 | English | Not rated yet | 888.00 | . 34136 How to Be a Conscious Eater | SophieEgan | SophieEgan | 7 hrs and 15 mins | 27-04-21 | English | Not rated yet | 562.00 | . 6549 Els silencis de la boca de la mina [The Silenc... | AndreuSotorra | JoanMora | 4 hrs and 3 mins | 02-01-19 | catalan | Not rated yet | 537.00 | . Cleaning the stars columns . The stars column has three distinct format of values: . 5 out of 5 stars34 ratings | 4.5 out of 5 stars38 ratings | Not rated yet | We handle the 3rd one efficiently using the Pandas Series and the replace method to replace with NaN values using the numpy library. Note: This doesn&#39;t use the str method and hence we use the inplace = True | As for the 1st and the 2nd one, we use Regex to split the string into two columns of stars and ratings.Note:I used the Regex101 as guide to use regular expression on the string. . | . data.stars.replace(&#39;Not rated yet&#39;, np.nan, inplace=True) data[[&#39;unknown&#39;,&#39;stars&#39;, &#39;ratings&#39;]] = data.stars.str.split(r&#39;( d*.? d s[a-z]+ s[a-z]+ s d+ s[a-z]+)&#39;, 1, expand=True, regex=True) . data.drop(&#39;unknown&#39;, axis=1, inplace=True) # Dropping the unknown column as it only consists of spaces and nan values . Changing Datatypes . Changing the price column to a float value . The price column has three distinct values: . Free | 3-digit value. Eg:839.00 | 4-digit value. Eg:1,230.00 | We replace 1st one with 0 | And for the 3rd one we remove the , as that blocks us to change the datatype to float | . data.price = data.price.str.replace(&#39;,&#39;, &#39;&#39;) data.price.replace(&#39;Free&#39;, 0, inplace=True) data.price = data.price.astype(&#39;float64&#39;) . Changing the ratings column to a float value . The ratings column has one value: . 23 ratings | We split the data at the -space- and drop the column which doesn&#39;t have the value and then change the datatype to float. Note:Ratings are generally whole numbers but since the column has null values it couldn&#39;t be changed to int and hence the choice for float . | . data[[&#39;ratings&#39;, &#39;unknown&#39;]] = data.ratings.str.split(&#39; &#39;, 1, expand=True) data.drop(&#39;unknown&#39;, axis=1, inplace=True) . data.ratings = data.ratings.str.replace(&#39;,&#39;, &#39;&#39;).astype(&#39;float64&#39;) . Changing the stars column to a float value . The stars column has one value: . 5 out of 5 stars | We split the data at the out and drop the extra column as all the values are rated out of 5 stars and then change the datatype to float. | . data[[&#39;stars&#39;, &#39;unknown&#39;]] = data.stars.str.split(&#39;out&#39;, 1, expand=True) data.drop(&#39;unknown&#39;, axis=1, inplace=True) . data.stars = data.stars.astype(&#39;float64&#39;) . Changing the releasedate to datetime object . data.releasedate = pd.to_datetime(data.releasedate) . Changing the time to datetime integer value of only minutes . The time column has 4 distinct values: . 1 hr | 1 min | 3 hrs and 40 mins | Less than 1 minute | For the 4th option we approx it to 1 min | We then replace the hrs to hr and mins to min, as that would help us genaralize it | . data.time = data.time.str.replace(&#39;Less than 1 minute&#39;, &#39;1 min&#39;) data.time = data.time.str.replace(&#39;mins&#39;, &#39;min&#39;) data.time = data.time.str.replace(&#39;hrs&#39;, &#39;hr&#39;) data.head(3) . name author narrator time releasedate language stars price ratings . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 2 hr and 20 min | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 13 hr and 8 min | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | . 2 The Deep End | JeffKinney | DanRussell | 2 hr and 3 min | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | . Here, we split the time twice, once to separate the hour and again to separate the minutes. This again uses Regex as that makes working with strings extremly easy and handy. . Note:It&#39;s not necessary to split it twice and can be done once by reusing mins however this makes it easier to read and understand. . data[[&#39;unknown&#39;, &#39;hour&#39;, &#39;mins&#39;]] = data[&#39;time&#39;].str.split(r&#39;( d+ hr)&#39;, expand=True, regex=True) data.drop([&#39;unknown&#39;, &#39;mins&#39;], axis =1, inplace=True) . data[[&#39;hr&#39;, &#39;minutes&#39;, &#39;unknown&#39;]] = data[&#39;time&#39;].str.split(r&#39;( d+ min)&#39;, expand=True, regex=True) data.drop([&#39;unknown&#39;, &#39;hr&#39;], axis =1, inplace=True) . Note:We see that we have None values and not np.nan values after splitting the string. We use .applymap() to map the lambda function and them sum them up to see the count of None values. An easier way to find what values you have in a Pandas Series is to run df.name_of_column.unique() to see all unique values. To count the number of unique values in a Pandas Series run df.name_of_column.nunique(). . data.applymap(lambda x: x is None).sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 0 price 0 ratings 0 hour 13406 minutes 1343 dtype: int64 . We fill None values the same as filling Nan values i.e. with fillna() . data.hour.fillna(value=&#39;0 hr&#39;, inplace=True) data.minutes.fillna(value=&#39;0 min&#39;, inplace=True) . data.applymap(lambda x: x is None).sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 0 price 0 ratings 0 hour 0 minutes 0 dtype: int64 . data.head(3) . name author narrator time releasedate language stars price ratings hour minutes . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 2 hr and 20 min | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | 2 hr | 20 min | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 13 hr and 8 min | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | 13 hr | 8 min | . 2 The Deep End | JeffKinney | DanRussell | 2 hr and 3 min | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | 2 hr | 3 min | . Now that we don&#39;t have any null values, we remove the string associated with the numbers - hr from the hour columns and min from the minutes column. To convert the entire time from hours &amp; minutes --&gt; minutes, we need to multiply the hours by 60 and then add the minutes. . After removing the string object we turn the value to an integer and use the .mulitply() method to multiply the Pandas Series. . | Finally, we add the minutes and hour column replacing the time column while dropping the hour and minutes column. . | . data.hour = data.hour.str.replace(&#39;hr&#39;, &#39;&#39;).astype(int).multiply(60) data.minutes = data.minutes.str.replace(&#39;min&#39;, &#39;&#39;).astype(int) data[&#39;time&#39;] = data.minutes + data.hour . data.drop([&#39;hour&#39;, &#39;minutes&#39;], axis=1, inplace=True) . data.head(3) . name author narrator time releasedate language stars price ratings . 0 Geronimo Stilton #11 &amp; #12 | GeronimoStilton | BillLobely | 140 | 2008-04-08 | English | 5.0 | 468.0 | 34.0 | . 1 The Burning Maze | RickRiordan | RobbieDaymond | 788 | 2018-01-05 | English | 4.5 | 820.0 | 41.0 | . 2 The Deep End | JeffKinney | DanRussell | 123 | 2020-06-11 | English | 4.5 | 410.0 | 38.0 | . Replacing the NaN values . We are almost done with cleaning our data however we still have Nan values. While we can have NaN values as it could portray the realistic way on how the data is represented but we would evnetually need to replace it with some value when analysing or visulizating the data. . In majority number of cases, I&#39;ve seen NaN values being replaced by mean or median which in this case wouldn&#39;t be of much help, as the audiobooks doesn&#39;t actually have a rating or star. It&#39;s much preferable to replace the value with zero. . data.isna().sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 72417 price 0 ratings 72417 dtype: int64 . We see an equal number of missing values, just as we expected on the stars and ratings column. To replace then with 0 we can simple write: . data.fillna(0, inplace=True) . We can see that we have no missing values now! Great! To check, we can simply run a sample() and it would show us. Note: sample() select a row randomly, you can pass in a value to get that many number of randomly selected rows. . data.isna().sum() . name 0 author 0 narrator 0 time 0 releasedate 0 language 0 stars 0 price 0 ratings 0 dtype: int64 . data.sample(3) . name author narrator time releasedate language stars price ratings . 40951 Шейх Мансур | АнатолийВиноградов | ВсеволодКузнецов | 61 | 2020-12-21 | russian | 0.0 | 99.0 | 0.0 | . 20151 Life | KeithRichards | StephanRemmler | 400 | 2010-04-11 | german | 0.0 | 367.0 | 0.0 | . 51989 The Ship of Silence | AlbertR.Wetjen | JeffHarding | 52 | 2022-02-18 | English | 0.0 | 53.0 | 0.0 | . Finally, we can view the entire infomation of the cleaned DataFrame using .info() . data.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 87489 entries, 0 to 87488 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 name 87489 non-null object 1 author 87489 non-null object 2 narrator 87489 non-null object 3 time 87489 non-null int64 4 releasedate 87489 non-null datetime64[ns] 5 language 87489 non-null object 6 stars 87489 non-null float64 7 price 87489 non-null float64 8 ratings 87489 non-null float64 dtypes: datetime64[ns](1), float64(3), int64(1), object(4) memory usage: 6.0+ MB . Saving the cleaned dataset . We have cleaned our dataset, and now to save it we use .to_csv() function providing the name of the csv file while setting the index to False. . Important:Not setting the index to False would generate an extra column in the csv with row numbers i.e. 0-87488. . data.to_csv(&#39;audible_cleaned.csv&#39;, index=False) .",
            "url": "https://snehangsude.github.io/xSpace/audible/data_wrangling/data_cleaning/tabular_data/2022/04/11/audible-cleaner.html",
            "relUrl": "/audible/data_wrangling/data_cleaning/tabular_data/2022/04/11/audible-cleaner.html",
            "date": " • Apr 11, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "The Brotherhood of : `__str__` & `__repr__`",
            "content": "Diving in the nitty-gritty details of Python introduces us to Dunder Methods. Dunder means &quot;double underscores&quot; as it starts and ends with two underscores. A dunder method acts as a contract between the Python interpreter and the person who made a particular Python class. . For example, the len method, it helps us with the length of any given string or list or a dictionary, however, it uses a dunder method len. Since the length of something is fundamental to any programming language it was made a built-in method but nonetheless, it internally delegates the task to len. . integers = [1, 2, 3, 4, 5] . print(len(integers)) . 5 . print(integers.__len__()) . 5 . There are quite a few built-in functions that internally use dunder methods to work, such as indexing which uses __getitem__, or print which uses __str__. If you are interested to know about all dunder methods here&#39;s a good resource: Dunder Methods. . The Difference . Understanding __str__ &amp; __repr__ allows us greater control for us to not only edit and upgrade classes but also to debug and create libraries. In a nutshell, if I had to explain to you about __str__ or __repr__ they both do the same thing i.e. they print an output. However, __repr__ is mostly used by programmers to debug, and __str__ is for the users using the program. Let&#39;s dive in to see how exactly are they both different and learn about when to use which! . repr(&#39;Triceratops&#39;) . &#34;&#39;Triceratops&#39;&#34; . str(&#39;Triceratops&#39;) . &#39;Triceratops&#39; . Looking at the above lines of code, there isn&#39;t much difference apart from the fact that repr(&#39;Triceratops&#39;) throws us an output which is within a double-inverted comma (&quot;&quot;) and then the string within a single-inverted (&#39;&#39;) comma. As for the str(&#39;Triceratops&#39;) it&#39;s within a single-inverted comma(&#39;&#39;). If you ask me, that&#39;s not even a difference as both of them do the same exact thing and there isn&#39;t much difference. . Let&#39;s look at something a bit more interesting. . import datetime . current_time = datetime.datetime.now() print(current_time) . 2022-03-03 02:10:02.973209 . str(current_time) . &#39;2022-03-03 02:10:02.973209&#39; . repr(current_time) . &#39;datetime.datetime(2022, 3, 3, 2, 10, 2, 973209)&#39; . Fascinating, isn&#39;t it! While using the datetime library we created a variable current_time which stores as the variable says, the current time. Running a print statement gives us an output that is similar to the output when we use the current_time variable inside the str() function. A user-friendly output of the variable giving is the year-month-date hour:minutes:seconds. . However, using the same variable inside the repr() function gives us an entirely different output. It tells us that it&#39;s a datetime object which holds the values (year, month, day, hour, minutes, seconds, microseconds). A developer-friendly output that provides adequate information for a developer to understand. . The Brotherhood . While it may be intriguing to prefer one over another, truth be told, we need both of them to make sure they cover both cases. The general idea is to make the __repr__ function help you as much as you can with maximum details. While the __str__ function with the minimum details which a user can read or understand. For example: . Defining a class: . class Dinosaur: def __init__(self, name): self.name = name def __repr__(self): return (f&#39;{self.name.__class__.__name__}({self.name})&#39;) def __str__(self): return (f&#39;{self.name}&#39;) . dino = Dinosaur(1) print(dino) . 1 . str(dino) . &#39;1&#39; . repr(dino) . &#39;int(1)&#39; . . Note: __class__ and __name__ represents the name of the class the name belongs to. . Conclusion . Now that, you have got a grasp into what __repr__ &amp; __str__ does, you are one step closer to debugging your own code. Try creating a class that gives you all the information using repr() but only the necessary one using str(). . If you are interested to know about how datetime wrote their library __repr__ and __str__ function, you can see the source code here. It might be overwhelming when you look at the code but try to search through the document to find __str__ and __repr__. Hint: Use Ctrl + F. This will give you a broader idea of how these functions are different, yet so similar. . Oh! Something to note, Jupyter notebooks use __repr__ when the output is requested without the print statement. . dino . int(1) . You can view my other articles here. I would much like to connect with you, if you would like to do so too, please connect with me on Twitter. .",
            "url": "https://snehangsude.github.io/xSpace/python/dunder_method/oop/2022/03/03/first.html",
            "relUrl": "/python/dunder_method/oop/2022/03/03/first.html",
            "date": " • Mar 3, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://snehangsude.github.io/xSpace/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://snehangsude.github.io/xSpace/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Hi, I’m Snehangsu De. I am a Data Analyst based in India. I love working with data while creating aesthetic, sometimes interactive data visualizations. The idea is to make decision making easier with the use of data and provide insights into the story, the data tells us. Normally, I work with Python, while recently I’m also diving into the Julia programming language. . This blog contains Notebooks, few topics which I write about are below: . Kaggle Notebooks | Tree-based modelling notebooks | Deep Learning Notebooks | Miscellaneous, which normally contains tougher concepts explained in code format. | . I have an additional blog in Hashnode, you can find it here.This contains hard to understand concepts explained in a visual way. . Additionally, you can view my website here, which contains my public projects. .",
          "url": "https://snehangsude.github.io/xSpace/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://snehangsude.github.io/xSpace/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}